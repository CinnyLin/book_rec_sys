{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Collaborative Filtering"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Collaborative filtering considers users’ opinion on different products and recommends the best products based on the products’ previous rankings and the opinion of other similar types of users. \n",
    "* The good side is that this method does not rely on knowledge of the product.\n",
    "* The down side is that it is not achievable for new products where it has no ratings yet. (Can solve by using ratings data from other platforms on the same product?)\n",
    "* Also, it requires all user community to be active and may suffer from sparsity problem."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Different types of collaborative filtering:\n",
    "\n",
    "**Non-probabilistic algorithm**\n",
    "* Memory-based\n",
    "    * User-based \n",
    "    * Item-based \n",
    "* Model-based \n",
    "\n",
    "**Probabilistic algorithm**\n",
    "* Bayesian-network model\n",
    "* EM algorithm"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Issues in collaborative filtering:\n",
    "\n",
    "* Sparseness in user-item matrix (sparsity=$1-|R|/|I|*|U|$)\n",
    "* Cold start: \n",
    "    * How to recommend a new video to users?\n",
    "    * What to recommend to new users?\n",
    "* Cold start solutions:\n",
    "    * Suggest or ask users to rate products\n",
    "    * Default voting for products\n",
    "    * Content-based or demographic"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Implementation (with `surprise`)\n",
    "\n",
    "**cross validation**\n",
    "- `cross_validate()`\n",
    "    - `KFold()`\n",
    "    - `RepeatedKFold()`\n",
    "    - `ShuffleSplit()`\n",
    "    - `LeaveOneOut()`\n",
    "- `train_test_split()` and `test()`\n",
    "- `build_full_trainset()` and `predict()`\n",
    "\n",
    "<span style=\"color:red\">What does build_full_trainset mean?? can i use train_test_split and then cross_validate on trainset and then predict testset?</span>\n",
    "\n",
    "<span style=\"color:red\">For implementation, should i also try out different cross validating methods?</span>\n",
    "\n",
    "**Parameter search**\n",
    "- `GridSearchCV()`\n",
    "\n",
    "**Evaluation**\n",
    "\n",
    "\n",
    "\n",
    "Source: [surprise documentation](https://surprise.readthedocs.io/en/stable/getting_started.html)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### import requirements"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import library\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import scipy as sp\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "from surprise import Dataset\n",
    "from surprise import Reader\n",
    "from surprise import SVDpp\n",
    "from surprise import KNNWithMeans\n",
    "from surprise.model_selection import cross_validate\n",
    "from surprise.model_selection import KFold\n",
    "from surprise.model_selection import train_test_split\n",
    "from surprise.model_selection import GridSearchCV\n",
    "from surprise import accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>User-ID</th>\n",
       "      <th>ISBN</th>\n",
       "      <th>Book-Rating</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>276725</td>\n",
       "      <td>034545104X</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>276726</td>\n",
       "      <td>0155061224</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>276727</td>\n",
       "      <td>0446520802</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   User-ID        ISBN  Book-Rating\n",
       "0   276725  034545104X            0\n",
       "1   276726  0155061224            5\n",
       "2   276727  0446520802            0"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# load data\n",
    "df = pd.read_csv('books/Ratings.csv')\n",
    "df.head(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### data preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.columns = ['uid', 'bid', 'rating']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1149780, 3)"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "uid       0\n",
       "bid       0\n",
       "rating    0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "count    1.149780e+06\n",
       "mean     2.866950e+00\n",
       "std      3.854184e+00\n",
       "min      0.000000e+00\n",
       "25%      0.000000e+00\n",
       "50%      0.000000e+00\n",
       "75%      7.000000e+00\n",
       "max      1.000000e+01\n",
       "Name: rating, dtype: float64"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['rating'].describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0     716109\n",
       "8     103736\n",
       "10     78610\n",
       "7      76457\n",
       "9      67541\n",
       "5      50974\n",
       "6      36924\n",
       "4       8904\n",
       "3       5996\n",
       "2       2759\n",
       "1       1770\n",
       "Name: rating, dtype: int64"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['rating'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.6228226269373272"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['rating'].value_counts()[0]/df.shape[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "More than half of our data do not have ratings, and we will have to drop them."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "433671"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.shape[0]-df['rating'].value_counts()[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "indices0 = df[df['rating']==0].index\n",
    "df1 = df.drop(indices0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(433671, 3)"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df1.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "After dropping the data without ratings, we still have `433671` entries, which is sufficient for us to build a recommender system.\n",
    "\n",
    "**P.S.** It is important to note that for the purpose of collaborative filtering, I have to drop data without ratings, but for example, if we are building recommender systems using other methods such as content-based algorithm, we can keep these entries."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.hist(df1['rating'])\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "count    433671.000000\n",
       "mean          7.601066\n",
       "std           1.843798\n",
       "min           1.000000\n",
       "25%           7.000000\n",
       "50%           8.000000\n",
       "75%           9.000000\n",
       "max          10.000000\n",
       "Name: rating, dtype: float64"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df1['rating'].describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Books without ratings or having users that never rated a book is the common issue in ecommerce businesses about **\"cold-start\"**, which collabortative filtering suffer. That is why we need content-based as well as popularity methods as complimentary solutions for recommender systems. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We might also need to drop users who have rated less than 10 books and books that have less than 50 ratings."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(73006, 3)"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# getting the new dataframe which contains books which has received 50 or more ratings\n",
    "df2 = df1.groupby(\"bid\").filter(lambda x:x['rating'].count()>=30)\n",
    "df2.shape #50000"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(38875, 3)"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# getting the new dataframe which contains users which has given 10 or more ratings\n",
    "df3 = df2.groupby(\"uid\").filter(lambda x:x['rating'].count()>=5)\n",
    "df3.shape #14060"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.033810815982187895"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df3.shape[0]/df.shape[0] # 0.012"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "After all the preprocessing, we only have `3%` left of our original data size, which is a managable size to deal with, but also means that this approach is not good enough and that we need other complementary approaches."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3215"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(set(df3['uid'])) # 784"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1147"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(set(df3['bid'])) # 537"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "df3.to_csv('recommender_cf.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "#sns.countplot(x='bid', data=df)\n",
    "#plt.title('Number of Ratings Books Received')\n",
    "#plt.xlabel('Books')\n",
    "#plt.ylabel('Ratings Counts')\n",
    "#plt.savefig('')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "#sns.countplot(x='uid', data=df)\n",
    "#plt.title('Number of Ratings Given by Users')\n",
    "#plt.xlabel('Users')\n",
    "#plt.ylabel('Ratings Counts')\n",
    "#plt.savefig('')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Data sets for Recommender Systems often have few items that contain the most ratings, whereas most of the items have very few ratings. This affects accuracy measurements as the accuracy predictions will generally be different on the popular items than the sparsely rated items. A solution to this problem is to give item specific weights toward each of the items when computing RSME or MAE, which are decided by the merchant. These could allow for a more accurate representation of how the Recommender System is evaluating all of the items"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### data loading"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "reader = Reader(rating_scale=(1,10))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = Dataset.load_from_df(df3[['uid', 'bid', 'rating']], reader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## cross-validation\n",
    "`cross_validate(algo, data, measures=[u'rmse', u'mae'], cv=None)`\n",
    "- `cv`: Determines how the data parameter will be split. If an int is passed, `KFold` is used with the appropriate `n_splits` parameter. Default is used with `n_splits=5`.\n",
    "- `verbose`: If `True` accuracy measures for each split are printed, as well as train and test times. Averages and standard deviations over all splits are also reported."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluating RMSE, MAE of algorithm SVDpp on 3 split(s).\n",
      "\n",
      "                  Fold 1  Fold 2  Fold 3  Mean    Std     \n",
      "RMSE (testset)    1.5567  1.5874  1.5670  1.5704  0.0128  \n",
      "MAE (testset)     1.1977  1.2057  1.1991  1.2008  0.0035  \n",
      "Fit time          8.57    8.55    8.57    8.57    0.01    \n",
      "Test time         0.48    0.41    0.39    0.43    0.04    \n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'test_rmse': array([1.55670324, 1.587386  , 1.56697047]),\n",
       " 'test_mae': array([1.19772939, 1.20566819, 1.19911776]),\n",
       " 'fit_time': (8.574179887771606, 8.552494764328003, 8.574100255966187),\n",
       " 'test_time': (0.47956418991088867, 0.4145498275756836, 0.39098525047302246)}"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "algo = SVDpp()\n",
    "cross_validate(algo, data, measures=['RMSE', 'MAE'], cv=3, verbose=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### more control over cross-validation\n",
    "- `KFold(n_splits=5, random_state=None, shuffle=True)`\n",
    "\n",
    "- `RepeatedKFold(n_splits=5, n_repeats=10, random_state=None)`: repeats `KFold` n times with different randomization.\n",
    "\n",
    "- `ShuffleSplit()`: contrary to other cross-validation strategies, random splits do not guarantee that all folds will be different.\n",
    "\n",
    "- `LeaveOneOut((n_splits=5, random_state=None, min_n_ratings=0)`: cross-validation iterator where each user has exactly one rating in the testset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RMSE: 1.5631\n",
      "RMSE: 1.5778\n",
      "RMSE: 1.5681\n"
     ]
    }
   ],
   "source": [
    "algo = SVDpp()\n",
    "kf = KFold(n_splits=3)\n",
    "for trainset, testset in kf.split(data):\n",
    "    algo.fit(trainset)\n",
    "    predictions = algo.test(testset)\n",
    "    accuracy.rmse(predictions, verbose=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### `train_test_split()`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "trainset, testset = train_test_split(data, test_size=.25)\n",
    "algo = SVDpp()\n",
    "predictions = algo.fit(trainset).test(testset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RMSE: 1.5511\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "1.5511283384941121"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "accuracy.rmse(predictions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### `build_full_trainset()`"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### item_based"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Estimating biases using als...\n",
      "Computing the pearson_baseline similarity matrix...\n",
      "Done computing similarity matrix.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<surprise.prediction_algorithms.knns.KNNWithMeans at 0x12d06ac70>"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "trainset = data.build_full_trainset()\n",
    "\n",
    "algo = KNNWithMeans(k=5, sim_options={'name': 'pearson_baseline', 'user_based': False})\n",
    "algo.fit(trainset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_pred = algo.test(testset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RMSE: 0.0802\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.08017413021465068"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "accuracy.rmse(test_pred, verbose=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE:  0.0460\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.04595865514975558"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "accuracy.mae(test_pred, verbose=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### user_based"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Estimating biases using als...\n",
      "Computing the pearson_baseline similarity matrix...\n",
      "Done computing similarity matrix.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<surprise.prediction_algorithms.knns.KNNWithMeans at 0x12cd2b970>"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "trainset = data.build_full_trainset()\n",
    "\n",
    "algo = KNNWithMeans(k=5, sim_options={'name': 'pearson_baseline', 'user_based': True})\n",
    "algo.fit(trainset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_pred = algo.test(testset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RMSE: 0.0611\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.061108349053021774"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "accuracy.rmse(test_pred, verbose=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE:  0.0364\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.03640693418710542"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "accuracy.mae(test_pred, verbose=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Parameter Search\n",
    "`GridSearchCV(algo_class, param_grid, measures=[u'rmse', u'mae'], cv=None, refit=False, return_train_measures=False)`\n",
    "\n",
    "`RandomizedSearchCV`\n",
    "\n",
    "Parameters\n",
    "- `param_grid`\n",
    "\n",
    "        param_grid = {'bsl_options': {'method': ['als', 'sgd'],\n",
    "                              'reg': [1, 2]},\n",
    "              'k': [2, 3],\n",
    "              'sim_options': {'name': ['msd', 'cosine'],\n",
    "                              'min_support': [1, 5],\n",
    "                              'user_based': [False]}\n",
    "              }\n",
    "\n",
    "Attributes\n",
    "- `best_estimmator`\n",
    "- `best_score`\n",
    "- `best_params`\n",
    "- `cv_results`\n",
    "        results_df = pd.DataFrame.from_dict(gs.cv_results)\n",
    "- ..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "param_grid = {'n_epochs': [5, 10], 'lr_all': [0.002, 0.005],\n",
    "              'reg_all': [0.4, 0.6]}\n",
    "gs = GridSearchCV(SVDpp, param_grid, measures=['rmse', 'mae'], cv=3)\n",
    "gs.fit(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.5869606813188082\n"
     ]
    }
   ],
   "source": [
    "# best RMSE score\n",
    "print(gs.best_score['rmse'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'n_epochs': 10, 'lr_all': 0.005, 'reg_all': 0.4}\n"
     ]
    }
   ],
   "source": [
    "# combination of parameters that gave the best RMSE score\n",
    "print(gs.best_params['rmse'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>split0_test_rmse</th>\n",
       "      <th>split1_test_rmse</th>\n",
       "      <th>split2_test_rmse</th>\n",
       "      <th>mean_test_rmse</th>\n",
       "      <th>std_test_rmse</th>\n",
       "      <th>rank_test_rmse</th>\n",
       "      <th>split0_test_mae</th>\n",
       "      <th>split1_test_mae</th>\n",
       "      <th>split2_test_mae</th>\n",
       "      <th>mean_test_mae</th>\n",
       "      <th>std_test_mae</th>\n",
       "      <th>rank_test_mae</th>\n",
       "      <th>mean_fit_time</th>\n",
       "      <th>std_fit_time</th>\n",
       "      <th>mean_test_time</th>\n",
       "      <th>std_test_time</th>\n",
       "      <th>params</th>\n",
       "      <th>param_n_epochs</th>\n",
       "      <th>param_lr_all</th>\n",
       "      <th>param_reg_all</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1.669092</td>\n",
       "      <td>1.675901</td>\n",
       "      <td>1.672627</td>\n",
       "      <td>1.672540</td>\n",
       "      <td>0.002780</td>\n",
       "      <td>7</td>\n",
       "      <td>1.299553</td>\n",
       "      <td>1.302288</td>\n",
       "      <td>1.306747</td>\n",
       "      <td>1.302862</td>\n",
       "      <td>0.002965</td>\n",
       "      <td>7</td>\n",
       "      <td>2.144402</td>\n",
       "      <td>0.065682</td>\n",
       "      <td>0.416659</td>\n",
       "      <td>0.056014</td>\n",
       "      <td>{'n_epochs': 5, 'lr_all': 0.002, 'reg_all': 0.4}</td>\n",
       "      <td>5</td>\n",
       "      <td>0.002</td>\n",
       "      <td>0.4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1.670916</td>\n",
       "      <td>1.678003</td>\n",
       "      <td>1.674262</td>\n",
       "      <td>1.674394</td>\n",
       "      <td>0.002895</td>\n",
       "      <td>8</td>\n",
       "      <td>1.301055</td>\n",
       "      <td>1.303923</td>\n",
       "      <td>1.307969</td>\n",
       "      <td>1.304316</td>\n",
       "      <td>0.002836</td>\n",
       "      <td>8</td>\n",
       "      <td>2.152929</td>\n",
       "      <td>0.114597</td>\n",
       "      <td>0.392014</td>\n",
       "      <td>0.049973</td>\n",
       "      <td>{'n_epochs': 5, 'lr_all': 0.002, 'reg_all': 0.6}</td>\n",
       "      <td>5</td>\n",
       "      <td>0.002</td>\n",
       "      <td>0.6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1.619604</td>\n",
       "      <td>1.624127</td>\n",
       "      <td>1.624651</td>\n",
       "      <td>1.622794</td>\n",
       "      <td>0.002266</td>\n",
       "      <td>3</td>\n",
       "      <td>1.262690</td>\n",
       "      <td>1.263602</td>\n",
       "      <td>1.269076</td>\n",
       "      <td>1.265123</td>\n",
       "      <td>0.002820</td>\n",
       "      <td>3</td>\n",
       "      <td>2.082210</td>\n",
       "      <td>0.074859</td>\n",
       "      <td>0.375560</td>\n",
       "      <td>0.041545</td>\n",
       "      <td>{'n_epochs': 5, 'lr_all': 0.005, 'reg_all': 0.4}</td>\n",
       "      <td>5</td>\n",
       "      <td>0.005</td>\n",
       "      <td>0.4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1.624315</td>\n",
       "      <td>1.628819</td>\n",
       "      <td>1.628663</td>\n",
       "      <td>1.627266</td>\n",
       "      <td>0.002087</td>\n",
       "      <td>4</td>\n",
       "      <td>1.266856</td>\n",
       "      <td>1.267571</td>\n",
       "      <td>1.273524</td>\n",
       "      <td>1.269317</td>\n",
       "      <td>0.002989</td>\n",
       "      <td>4</td>\n",
       "      <td>2.114072</td>\n",
       "      <td>0.085498</td>\n",
       "      <td>0.401173</td>\n",
       "      <td>0.037537</td>\n",
       "      <td>{'n_epochs': 5, 'lr_all': 0.005, 'reg_all': 0.6}</td>\n",
       "      <td>5</td>\n",
       "      <td>0.005</td>\n",
       "      <td>0.6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1.632807</td>\n",
       "      <td>1.637000</td>\n",
       "      <td>1.636942</td>\n",
       "      <td>1.635583</td>\n",
       "      <td>0.001963</td>\n",
       "      <td>5</td>\n",
       "      <td>1.273117</td>\n",
       "      <td>1.273336</td>\n",
       "      <td>1.278990</td>\n",
       "      <td>1.275147</td>\n",
       "      <td>0.002719</td>\n",
       "      <td>5</td>\n",
       "      <td>4.326846</td>\n",
       "      <td>0.104060</td>\n",
       "      <td>0.394228</td>\n",
       "      <td>0.047052</td>\n",
       "      <td>{'n_epochs': 10, 'lr_all': 0.002, 'reg_all': 0.4}</td>\n",
       "      <td>10</td>\n",
       "      <td>0.002</td>\n",
       "      <td>0.4</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   split0_test_rmse  split1_test_rmse  split2_test_rmse  mean_test_rmse  \\\n",
       "0          1.669092          1.675901          1.672627        1.672540   \n",
       "1          1.670916          1.678003          1.674262        1.674394   \n",
       "2          1.619604          1.624127          1.624651        1.622794   \n",
       "3          1.624315          1.628819          1.628663        1.627266   \n",
       "4          1.632807          1.637000          1.636942        1.635583   \n",
       "\n",
       "   std_test_rmse  rank_test_rmse  split0_test_mae  split1_test_mae  \\\n",
       "0       0.002780               7         1.299553         1.302288   \n",
       "1       0.002895               8         1.301055         1.303923   \n",
       "2       0.002266               3         1.262690         1.263602   \n",
       "3       0.002087               4         1.266856         1.267571   \n",
       "4       0.001963               5         1.273117         1.273336   \n",
       "\n",
       "   split2_test_mae  mean_test_mae  std_test_mae  rank_test_mae  mean_fit_time  \\\n",
       "0         1.306747       1.302862      0.002965              7       2.144402   \n",
       "1         1.307969       1.304316      0.002836              8       2.152929   \n",
       "2         1.269076       1.265123      0.002820              3       2.082210   \n",
       "3         1.273524       1.269317      0.002989              4       2.114072   \n",
       "4         1.278990       1.275147      0.002719              5       4.326846   \n",
       "\n",
       "   std_fit_time  mean_test_time  std_test_time  \\\n",
       "0      0.065682        0.416659       0.056014   \n",
       "1      0.114597        0.392014       0.049973   \n",
       "2      0.074859        0.375560       0.041545   \n",
       "3      0.085498        0.401173       0.037537   \n",
       "4      0.104060        0.394228       0.047052   \n",
       "\n",
       "                                              params  param_n_epochs  \\\n",
       "0   {'n_epochs': 5, 'lr_all': 0.002, 'reg_all': 0.4}               5   \n",
       "1   {'n_epochs': 5, 'lr_all': 0.002, 'reg_all': 0.6}               5   \n",
       "2   {'n_epochs': 5, 'lr_all': 0.005, 'reg_all': 0.4}               5   \n",
       "3   {'n_epochs': 5, 'lr_all': 0.005, 'reg_all': 0.6}               5   \n",
       "4  {'n_epochs': 10, 'lr_all': 0.002, 'reg_all': 0.4}              10   \n",
       "\n",
       "   param_lr_all  param_reg_all  \n",
       "0         0.002            0.4  \n",
       "1         0.002            0.6  \n",
       "2         0.005            0.4  \n",
       "3         0.005            0.6  \n",
       "4         0.002            0.4  "
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "results_df = pd.DataFrame.from_dict(gs.cv_results)\n",
    "results_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Evaluation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### MAE (mean absolute error)\n",
    "\n",
    "Mean Average Error (MAE) does not give any bias to extrema in error terms. If there are outliers or large error terms, it will weigh those equally to the other predictions. Therefore, MAE should be preferred when looking toward rating accuracy when you’re not really looking toward the importance of outliers. To get a holistic view or representation of the Recommender System, use MAE."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### RMSE (root mean squared error)\n",
    "\n",
    "Root Mean Squared Error tends to disproportionately penalize large errors as the residual (error term) is squared. This means RMSE is more prone to being affected by outliers or bad predictions.\n",
    "\n",
    "MAE can only accurately recreate 0.8 of the data set. RSME is a lot more mathematically convenient whenever calculating distance, gradient, or other metrics. That’s why most cost functions in Machine Learning avoid using MAE and rather use sum of squared errors or Root Means Squared Error.\n",
    "\n",
    "By definition, RMSE will never be as small as MAE. [This paper](https://gmd.copernicus.org/articles/7/1247/2014/gmd-7-1247-2014.pdf) establishes that both metrics are useful in evaluating algorithms."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## How to get top-N recommendations for each user\n",
    "Source: [documentation](https://surprise.readthedocs.io/en/stable/FAQ.html)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We first train an SVD algorithm on the whole dataset, and then predict all the ratings for the pairs (user, item) that are not in the training set. We then retrieve the top-10 prediction for each user."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.8.1 64-bit",
   "language": "python",
   "name": "python38164bit0209044da7c742dab8314e0953beb93b"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
